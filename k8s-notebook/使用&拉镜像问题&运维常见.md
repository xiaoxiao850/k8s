# 使用&运维常见
## 拉取镜像 timeout
1. 拉取镜像 timeout

   ![image-20231205113834744](C:\Users\15313\AppData\Roaming\Typora\typora-user-images\image-20231205113834744.png)

   Failed to pull image "registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1"

   解决方法：

   - 查看部署yaml拉取镜像的策略是否是“always（总是从远端拉）”或者“IfNotPresent（查看本地没有再拉取）”。然后尝试本地拉取

   - 本地docker放置镜像加速。https://console.huaweicloud.com/swr/?agencyId=959e7c4ae9eb47b2bc5f6dfea736f099&region=cn-east-3&locale=zh-cn#/swr/mirror 。

     ![image-20231205114102735](C:\Users\15313\AppData\Roaming\Typora\typora-user-images\image-20231205114102735.png)

     ```
     {
         "registry-mirrors": [ "https://b6967b9dc64b42a19e77b25eff3b4bab.mirror.swr.myhuaweicloud.com" ]
     }
     ```

     

     在本地(该pod被调度到的节点上)拉取：

     ```bash
     $ sudo docker search csi-node-driver-registrar
     #选取
     $ sudo docker pull dyrnq/csi-node-driver-registrar:v2.5.1
     #重命名 为目标镜像名，并删除原来的
     $ sudo docker tag dyrnq/csi-node-driver-registrar:v2.5.1  registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1
     $ sudo docker rmi dyrnq/csi-node-driver-registrar:v2.5.1
     
     ```

     

   - 

     在主机间传递镜像

     

     ```bash
     $ sudo docker save -o csi_images.tar registry.k8s.io/sig-storage/csi-provisioner:v3.2.0 registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.5.1
     
     $ scp csi_images.tar aiedge@xx-test-node236:/path/to/destination/
     
     $ sudo docker load -i /path/to/destination/csi_images.tar
     
     ```
   
     
   
   - ctr -n k8s.io i ls这是查看这个命名空间下的镜像的命令 
    sudo ctr -n k8s.io images import csi_images.tar **加载 Docker 镜像到 containerd**


## 私有仓库推拉镜像

### 配置 docker

```shell
IMAGE_REGISTRY=${IMAGE_REGISTRY:-registry.aiedge.ndsl-lab.cn}

# prepare docker
if [ ! -d "/root/.docker" ]; then
    mkdir /root/.docker
fi
bash -c "cat > /root/.docker/config.json" <<EOF
{
  "auths": {
    "registry.aiedge.ndsl-lab.cn": {
      "auth": "YWllZGdlOmFpZWRnZTgwMjA="
    },
    "registry.aiedge.lomot.top": {
      "auth": "YWllZGdlOmFpZWRnZTgwMjA="
    }
  }
}
EOF

bash -c "cat > /etc/docker/daemon.json" <<EOF
{
    "insecure-registries":[ "${IMAGE_REGISTRY}" ]
}
EOF
systemctl restart docker

```

然后部署 `image-pull-secret.yaml`，然后就可以用 docker 从 `registry.aiedge.ndsl-lab.cn` 推拉镜像了

### 配置 containerd

首先需要配置 `/etc/containerd/config.toml` ，然后使用 `crictl` 拉镜像

#### ctr 和 crictl

* **ctr** 是 **containerd** 的一个客户端工具。

* **crictl** 是 **CRI（容器运行时）** 的`命令行接口`，kubernetes 通过它来调用节点上的`容器运行时`，实现这个接口的容器运行时，可能是docker，也可能containerd，也可能Podman，kubernetes并不关心。

从结果上看，可以认为 crictl 是基于 kubernetes 的。

此外，**ctr 不使用 CRI API，因此不会从 `[plugins."io.containerd.grpc.v1.cri"]` 中读取任何配置！**

**如果要使用 `/etc/containerd/config.toml` 中的 CRI 配置，必须使用 crictl**

### config.toml 配置

初始配置：

```toml
[plugins."io.containerd.grpc.v1.cri".registry]
      config_path = ""

      [plugins."io.containerd.grpc.v1.cri".registry.auths]

      [plugins."io.containerd.grpc.v1.cri".registry.configs]

      [plugins."io.containerd.grpc.v1.cri".registry.headers]

      [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
```

修改之后：

```toml
[plugins."io.containerd.grpc.v1.cri".registry]
      config_path = ""

      [plugins."io.containerd.grpc.v1.cri".registry.auths]

      [plugins."io.containerd.grpc.v1.cri".registry.configs]
        [plugins."io.containerd.grpc.v1.cri".registry.configs."registry.aiedge.ndsl-lab.cn".auth]
          username = "aiedge"
          password = "aiedge8020"
          auth = ""
          identitytoken = ""

      [plugins."io.containerd.grpc.v1.cri".registry.headers]

      [plugins."io.containerd.grpc.v1.cri".registry.mirrors]
```

在使用 crictl 之前，添加配置（生成的配置文件在 `etc/crictl.yaml`）：

```bash
crictl config runtime-endpoint unix:///var/run/containerd/containerd.sock
crictl config image-endpoint unix:///var/run/containerd/containerd.sock
```





## 使用 `nerdctl` 来登录私有仓库

### 安装 nerdctl

二进制安装：[下载地址](https://github.com/containerd/nerdctl/releases)

版本：v1.7.4

```bash
tar Cxzvvf /usr/local nerdctl-full-1.7.4-linux-amd64.tar.gz
```

登录私有仓库：

```bash
nerdctl --insecure-registry login -u aiedge -p aiedge8020 registry.aiedge.ndsl-lab.cn
```

拉取镜像：

```bash
nerdctl -n k8s.io pull registry.aiedge.ndsl-lab.cn/mysql:5.7
```

## The connection to the server <HOST>:6443 was refused
### 问题描述
由于断电停机，kubernetes集群挂掉，使用任意kubectl 命令会报错：The connection to the server ip:6443 was refused - did you specify the right host or port，重启kubelet也不能恢复，etcd读取数据报错，数据文件损坏
### 排查过程
首先检查服务是否启动有无报错
`systemctl status kubelet `
```bash
root@master-test-251:/home/aiedge/distributed-inference/pipeline-operator# systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: active (running) since Mon 2024-05-06 01:34:28 UTC; 15min ago
       Docs: https://kubernetes.io/docs/home/
   Main PID: 2559 (kubelet)
      Tasks: 17 (limit: 7073)
     Memory: 35.5M
     CGroup: /system.slice/kubelet.service
             └─2559 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubele>

May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.200823    2559 kubelet.go:2448] "Error getting node" err="node \"master-test-251\" not found"
May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.301923    2559 kubelet.go:2448] "Error getting node" err="node \"master-test-251\" not found"
May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.402917    2559 kubelet.go:2448] "Error getting node" err="node \"master-test-251\" not found"
May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.503315    2559 kubelet.go:2448] "Error getting node" err="node \"master-test-251\" not found"
May 06 01:50:13 master-test-251 kubelet[2559]: I0506 01:50:13.505879    2559 kubelet_node_status.go:70] "Attempting to register node" node="master-test-251"
May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.507615    2559 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https:/>
May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.603554    2559 kubelet.go:2448] "Error getting node" err="node \"master-test-251\" not found"
May 06 01:50:13 master-test-251 kubelet[2559]: E0506 01:50:13.703904    2559 kubelet.go:2448] "Error getting node" err="node \"master-test-251\" not found"
```
有报错，找不到master节点，继续查看kubelet还是有报错
`journalctl -u kubelet`
```bash
root@master-test-251:/home/aiedge/distributed-inference/pipeline-operator# journalctl -u kubelet
-- Logs begin at Fri 2023-12-22 06:52:10 UTC, end at Mon 2024-05-06 01:51:25 UTC. --
Jan 30 08:14:56 master-test-251 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 30 08:14:57 master-test-251 systemd[1]: kubelet.service: Current command vanished from the unit file, execution of the command list won't be resumed.
Jan 30 08:14:57 master-test-251 systemd[1]: Stopping kubelet: The Kubernetes Node Agent...
Jan 30 08:14:57 master-test-251 systemd[1]: kubelet.service: Succeeded.
Jan 30 08:14:57 master-test-251 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jan 30 08:14:57 master-test-251 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 30 08:14:57 master-test-251 kubelet[20076]: E0130 08:14:57.479744   20076 run.go:74] "command failed" err="failed to load kubelet config file, error: failed to l>
Jan 30 08:14:57 master-test-251 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jan 30 08:14:57 master-test-251 systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jan 30 08:15:01 master-test-251 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jan 30 08:15:01 master-test-251 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 30 08:15:01 master-test-251 kubelet[20292]: E0130 08:15:01.989937   20292 run.go:74] "command failed" err="failed to load kubelet config file, error: failed to l>
Jan 30 08:15:02 master-test-251 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Jan 30 08:15:02 master-test-251 systemd[1]: kubelet.service: Failed with result 'exit-code'.
Jan 30 08:15:12 master-test-251 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 1.
Jan 30 08:15:12 master-test-251 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jan 30 08:15:12 master-test-251 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jan 30 08:15:12 master-test-251 kubelet[20406]: E0130 08:15:12.619894   20406 run.go:74] "command failed" err="failed to load kubelet config file, error: failed to l>
Jan 30 08:15:12 master-test-251 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
```